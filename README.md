# Backblaze Data Analysis

A collection of scripts to prepare and process data published by Backblaze, to
generate failure rate curves over the age of a disk. The scripts needed for the
final generation of plots are kept in [failure-analysis repo][].

The steps described below assumes the presence of directories `2014`, `2015`,
`2016` and `2017` within [`data` directory][], containing [Hard Drive Test Data
from Backblaze][backblaze] in csv format (i.e. after extracted them).

[failure-analysis repo]: https://gitlab.com/johncf/failure-analysis
[`data` directory]: ./data
[backblaze]: https://www.backblaze.com/b2/hard-drive-test-data.html

### Prepare Database: `dbpopulate.sh`

`dbpopulate.sh`, when executed, will create a Postgres database named
`backblaze` and a table named `raw_logs` in it. It proceeds to populate it with
data from [`data` directory][].

This uses `filter_csv.py` to create a csv file each for every month, which only
contains those fields necessary for the database. It then performs a [`COPY`][]
from the newly created csv file into the `raw_logs` table.

[`COPY`]: https://www.postgresql.org/docs/current/static/sql-copy.html

### Process Data: `process.sh`

`process.sh` crunches the data to produce two output files: `fails.csv` and
`obs.csv`. These files can be passed to `basic-plot.py` script from
[failure-analysis repo][failure-analysis] to generate annualized failure rate plot
against the age of the disk for the model of interest specified in `views.sql`.

Edit `views.sql` before running this if you want to specify another disk model
of interest. At the time of writing this, there was only one disk model with
enough data to generate a failure rate curve with low noise.

[failure-analysis]: https://gitlab.com/johncf/failure-analysis

### Results

Below are the plots generated by [`basic-plot.py`][] for various disk models
from Backblaze dataset. In the plots below, power-on hours from data is
converted to power-on years. Thus the resulting failure rate is on an yearly
basis; more specifically, the unit we use is "Annualized Failure Rate" (AFR) in
percentage.

[`basic-plot.py`]: https://gitlab.com/johncf/failure-analysis/blob/master/basic-plot.py

#### ST4000DM000

**Total disk-years observed:** 87,647 <br>
**Total failures observed:** 2,587 <br>
**Mean AFR over lifetime:** 3.0%

![fr-1](https://i.imgur.com/VRJQG8ql.png)

#### ST3000DM001

**Total disk-years observed:** 3481 <br>
**Total failures observed:** 1454 <br>
**Mean AFR over lifetime:** 42%

![fr-2](https://i.imgur.com/Y4kzn5Yl.png)

**Comments:** Abnormally high failure rate. The graph below shows the number of
failures reported daily for this model which is too high for the number of
disks deployed. For comparison, the same for the previous model is also shown
below.

![fpd-2](https://i.imgur.com/aQFithX.png)
![fpd-1](https://i.imgur.com/QLwuqOW.png)

This might be due to the failure detection system being too conservative and
making false alarms for behaviors that the manufacturer might consider
"normal."

#### ST31500541AS

**Total disk-years observed:** 2825 <br>
**Total failures observed:** 274 <br>
**Mean AFR over lifetime:** 9.7%

![fr-3](https://i.imgur.com/LPIvrzGl.png)

#### Hitachi HDS722020ALA330

**Total disk-years observed:** 11898 <br>
**Total failures observed:** 202 <br>
**Mean AFR over lifetime:** 1.7%

![fr-4](https://i.imgur.com/krPjb8Bl.png)

#### WDC WD30EFRX

**Total disk-years observed:** 3301 <br>
**Total failures observed:** 166 <br>
**Mean AFR over lifetime:** 5.0%

![fr-5](https://i.imgur.com/fsYYpLvl.png)
